
# SLAM 14讲 高翔


# 1 - 3 章 简单回顾

## 第一章 

SLAM的两个主要问题， 1. 明白自身的状态（位置）， 2. 了解外在的环境 （建图）。
可以通过两类方式来实现： 一是通过携带于机器人本体上的传感器；而是通过安装于环境当中的标志。

==单目相机==： 通过二维信息记录了世界，但是损失了深度信息。但是可以通过相机的移动来确定物体得视差，然后来判断物体的**远近**，但是因为这个远近只是一个相对值，所以缺少一个尺度因子，单目图像无法确定这个真实尺度，又称为**尺度不确定性**。
==双目相机==：在单目相机的基础上，通过双目生成的**视差图**来对深度进行计算，但是他计算出来的结果也不是很准确的，同时双目相机能探测到的深度范围和基线相关，基线越大能测量到的物体就越远，同时他的计算量也比较大， 需要使用GPU或者FPGA设备进行加速，目前**计算量**是双目的主要问题之一。
==深度相机==： 也叫RGB-D相机，通过物理测量的手段，相比于双目相机节省了大量的计算资源。但是还存在测量范围窄、噪声大、视野小、易受日光干扰等因素，目前**主要用于室内**，室外较难应用。

#### 经典视觉SLAM框架

1. 传感器信息获取： 视觉SLAM中主要表现为相机图像的信息的读取和预处理。
2. 前端视觉里程计（Visual Odometry VO）：用于估计相邻图像间相机的运动，以及局部地图的样子。 VO 也被称为前端。
3. 后端非线性优化（Optimization） ： 对不同时刻的视觉里程计测量的相机位姿和回环信息进行优化，得到全局一致的轨迹和地图。
4. 回环检测 （Loop Closure Detection）：回环检测判断机器人是否到达过先前的位置， 如果检测到回环，会把信息给后端进行处理。
5. 建图（Mapping）： 根据估计的轨迹， 建立与任务要求对应的地图。包括度量地图和拓扑地图，两种。

==在视觉SLAM中， 前端和计算机视觉研究领域更为相关，比如图像的特征提取与匹配等，后端则主要是滤波与非线性优化算法。==




 